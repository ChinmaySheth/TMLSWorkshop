{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6392f326",
   "metadata": {},
   "source": [
    "# Building an End-to-End Web Application Integrated with Microsoft's Semantic Kernel and a Large Language Model\n",
    "\n",
    "## Notebook \\#1: Getting to know Microsoft Semantic Kernel & OpenAI LLMs\n",
    "\n",
    "Welcome to the first demo notebook for our workshop on MS Semantic Kernel! SK provides a framework for developing applications that invoke LLMs. Connections to OpenAI, Azure OpenAI, and HuggingFace models are supported. We will be demonstrating SK in conjunction with OpenAI models.\n",
    "\n",
    "**For more information, please refer to:**\n",
    "- Semantic Kernel on GitHub: https://github.com/microsoft/semantic-kernel\n",
    "- Semantic Kernel documentation: https://learn.microsoft.com/en-gb/semantic-kernel/ (Note that this focuses on the C# implementation)\n",
    "\n",
    "**Requirements:**\n",
    "- python >= 3.8\n",
    "- semantic_kernel (pip installable!)\n",
    "- An OpenAI API key (all new users have free credits to use in their first 3 months)\n",
    "\n",
    "If you have an OpenAI platform account, you can generate a new API key here: https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2814028",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a11e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAITextCompletion, OpenAIChatCompletion\n",
    "from semantic_kernel.utils.settings import openai_settings_from_dot_env\n",
    "\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d5870",
   "metadata": {},
   "source": [
    "## Initializing the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11101206",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = sk.Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32cde661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should edit the example .env file with your own OpenAI API key before running this command\n",
    "api_key, org_id = openai_settings_from_dot_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7fefc2",
   "metadata": {},
   "source": [
    "### Configuring OpenAI backend\n",
    "\n",
    "Recommended model options:\n",
    "- `text-davinci-003`: Most powerful InstructGPT model, \\$0.02 per 1000 tokens (~750 words)\n",
    "- `gpt-3.5-turbo`: Model behind ChatGPT, \\$0.002 per 1000 tokens\n",
    "\n",
    "The full list of OpenAI models and pricing is available here: https://openai.com/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e7af3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 cents per 1000 tokens (prompts and responses)\n",
    "#kernel.add_text_completion_service(\n",
    "#    \"text-davinci-003\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d816c854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<semantic_kernel.kernel.Kernel at 0x7f0ae841e820>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.2 cents per 1000 tokens (prompts and responses)\n",
    "kernel.add_chat_service(\n",
    "    \"gpt-3.5-turbo\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93857ec",
   "metadata": {},
   "source": [
    "## Testing the language model connection\n",
    "\n",
    "Before getting into designing semantic skills and prompt engineering, we should confirm that we have the kernel and model connection configuration set up properly. A short question with a short response is all that is needed here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e91c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit with your favourite book or series (released before 2021)\n",
    "prompt = \"Who is the author of the Foundation series?\"\n",
    "\n",
    "test_func = kernel.create_semantic_function(prompt, max_tokens=100, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d776cde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author of the Foundation series is Isaac Asimov.\n"
     ]
    }
   ],
   "source": [
    "answer = test_func()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499fd473",
   "metadata": {},
   "source": [
    "## Building semantic functions & skills\n",
    "\n",
    "SK encourages LLM prompt templating and reuse by bundling them into \"semantic functions.\" Prompts are regular strings and can contain zero, one, or multiple context variables indicated by double curly braces `{{}}` and `$variable_name`. When there is only one context variable, indicate it with `{{$input}}`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40b10d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with a simple prompt -- asking the LLM to write an email about a topic\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write an email about {{$input}}\n",
    "\"\"\"\n",
    "\n",
    "email_writer = kernel.create_semantic_function(prompt, max_tokens=1000, temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3162d8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Join us for a Free Community Event in High Park!\n",
      "\n",
      "Dear [Recipient],\n",
      "\n",
      "We are excited to invite you to a free community event in High Park on [Date] from [Time] to [Time]. This event is open to everyone in the community and we hope to see you there!\n",
      "\n",
      "The event will take place at the High Park Amphitheatre and will feature a variety of activities for all ages. There will be live music, food vendors, face painting, and much more. We will also have a raffle with some great prizes, so be sure to enter for your chance to win.\n",
      "\n",
      "This event is a great opportunity to meet your neighbors and enjoy a fun day out in the park. We encourage you to bring your family and friends and make a day of it. There will be plenty of space to relax and enjoy the beautiful surroundings of High Park.\n",
      "\n",
      "We hope to see you there and look forward to spending a fun-filled day with you. If you have any questions or would like more information about the event, please don't hesitate to contact us.\n",
      "\n",
      "Thank you for your time and we hope to see you soon!\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"a free community event in High Park\"\n",
    "\n",
    "output = email_writer(input_text)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee0607",
   "metadata": {},
   "source": [
    "### Aside: Prompt engineering\n",
    "\n",
    "Unless you are very lucky, you're not likely to get the perfect response to your request from the LLM on your first try. This is where prompt engineering comes in: experimenting with changes to your prompt to improve the model's response. Even small changes to the wording or formatting of a prompt can lead to very different model responses. A prompt that works well with one model may give totally different responses when used with another model. \n",
    "\n",
    "This isn't unique to using SK. Anytime you use or work with LLMs, you'll likely need to do some prompt engineering.\n",
    "\n",
    "Some approaches you can try with prompt engineering:\n",
    "  - Set the tone or explain the context\n",
    "  - Give specific requirements\n",
    "  - Add instructions for edge cases\n",
    "  - Show example inputs and responses (\"few shot learning\")\n",
    "  \n",
    "We will test these out with our basic email writing function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b7f6279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Join us for a Free Community Event in High Park!\n",
      "\n",
      "Dear [Recipient],\n",
      "\n",
      "I am excited to invite you to a free community event in High Park on [Date] from [Time] to [Time]. This event is aimed at bringing together the residents of our community to celebrate our beautiful park and the people who make it special.\n",
      "\n",
      "The event will feature a range of activities for all ages, including live music, food trucks, face painting, and much more. You will also have the opportunity to meet and interact with your neighbors and local officials, including myself.\n",
      "\n",
      "High Park is a true gem in our community, and this event is a great way to showcase its beauty and bring people together. I encourage you to come out and enjoy the festivities with your family and friends.\n",
      "\n",
      "Please feel free to share this invitation with your friends and family. We look forward to seeing you there!\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "[Your Name]\n",
      "\n",
      "[Your Title]\n",
      "\n",
      "[Your Contact Information]\n"
     ]
    }
   ],
   "source": [
    "# Setting the tone\n",
    "prompt = \"\"\"\n",
    "Draft an email from a local politician about {{$input}}\n",
    "\"\"\"\n",
    "\n",
    "email_writer = kernel.create_semantic_function(prompt, max_tokens=1000, temperature=0.3)\n",
    "output = email_writer(input_text)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84734844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Join me for a free community event in High Park!\n",
      "\n",
      "Dear neighbours,\n",
      "\n",
      "I am thrilled to invite you to a free community event in High Park on Saturday, August 14th from 11am-3pm. This event is a great opportunity for us to come together as a community and enjoy the beautiful outdoors while participating in fun activities and learning about local organizations.\n",
      "\n",
      "There will be something for everyone at this event, including live music, food trucks, face painting, and a bouncy castle for the kids. You can also take part in guided nature walks, learn about local wildlife, and meet representatives from community organizations who will be on hand to answer your questions and provide information about their services.\n",
      "\n",
      "This event is being organized by the City of Toronto in partnership with local community groups, and I am proud to support it. It's a great way for us to celebrate our community and all the wonderful things that make it special.\n",
      "\n",
      "To learn more about the event and to RSVP, please visit the City of Toronto website at https://www.toronto.ca/community-people/get-involved/community/community-events/high-park-community-event/. You can also follow the event on Facebook at https://www.facebook.com/events/1234567890.\n",
      "\n",
      "I hope to see you there!\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "[Your Name]\n",
      "\n",
      "[Your Title/Position]\n",
      "\n",
      "[Your Contact Information]\n"
     ]
    }
   ],
   "source": [
    "# Clarify instructions by giving specific requirements\n",
    "prompt = \"\"\"\n",
    "Draft an email from a local politician about {{$input}}. \n",
    "Address the email to 'Dear neighbours'. Include links to relevant websites.\n",
    "\"\"\"\n",
    "\n",
    "email_writer = kernel.create_semantic_function(prompt, max_tokens=1000, temperature=0.3)\n",
    "output = email_writer(input_text)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fddeba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irrelevant topic.\n"
     ]
    }
   ],
   "source": [
    "# Add instructions for edge cases\n",
    "prompt = \"\"\"\n",
    "Draft an email from a local politician about {{$input}}. \n",
    "If the topic above is not relevant to community updates or events,\n",
    "write 'Irrelevant topic' instead of an email.\n",
    "\"\"\"\n",
    "\n",
    "bad_input = \"tuna casserole\"\n",
    "\n",
    "email_writer = kernel.create_semantic_function(prompt, max_tokens=1000, temperature=0.3)\n",
    "output = email_writer(bad_input)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d012aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Register for Youth Sports Today!\n",
      "\n",
      "Dear Community Members,\n",
      "\n",
      "I hope this email finds you well. As we approach the end of summer, I wanted to remind you that registration for youth sports is now open. This is a great opportunity for your children to stay active, learn new skills, and make new friends.\n",
      "\n",
      "Our community offers a variety of sports programs for children of all ages, including soccer, basketball, baseball, and more. These programs are run by dedicated volunteers who are committed to providing a safe and fun environment for our youth.\n",
      "\n",
      "I encourage you to register your children for these programs as soon as possible. Not only will they benefit from the physical activity and social interaction, but they will also learn important life skills such as teamwork, sportsmanship, and perseverance.\n",
      "\n",
      "If you have any questions or concerns about the registration process, please do not hesitate to reach out to me or the program coordinators. We are here to help and ensure that every child has the opportunity to participate in youth sports.\n",
      "\n",
      "Thank you for your continued support of our community's youth programs.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "good_input = \"youth sports registration\"\n",
    "\n",
    "email_writer = kernel.create_semantic_function(prompt, max_tokens=1000, temperature=0.3)\n",
    "output = email_writer(good_input)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59232c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear residents,\n",
      "\n",
      "I wanted to let you know about an exciting community event happening in High Park next weekend. On Saturday, we will be hosting a family-friendly picnic with games, music, and food. This is a great opportunity to meet your neighbours and enjoy the beautiful park together. The event will start at 12 PM and go until 4 PM. Please bring your own blankets and chairs. We hope to see you there!\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your local councillor]\n"
     ]
    }
   ],
   "source": [
    "# Show example inputs and model responses (few-shot learning)\n",
    "# We're able to change the output style and length significantly by showing examples!\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write a short email from a local politician about a topic or event of local interest.\n",
    "\n",
    "Topic: ```Recycling```\n",
    "\n",
    "Email:\n",
    "Dear neighbours,\n",
    "\n",
    "Did you know that over 50% of the garbage collected in our city could have been recycled?\n",
    "You can learn this and other surprising trash facts in this month's edition of the city\n",
    "newsletter. Be sure to stick the waste sorting cheat sheet to your fridge for easy reference.\n",
    "You can also visit our website to look up the correct bin for hundreds of waste items.\n",
    "Together, we can cut down on landfill usage!\n",
    "\n",
    "Sincerely,\n",
    "\n",
    "[Deputy Mayor]\n",
    "\n",
    "Topic: ```Canada Day Fireworks```\n",
    "\n",
    "Email:\n",
    "Dear neighbours, \n",
    "\n",
    "Happy Canada Day! We are holding a celebration at City Hall starting at 3 PM. Fireworks\n",
    "will begin at 9:30 PM. There will be food, local vendors, musical performances, and lots\n",
    "more. Everyone is welcome. Admission is free but donations to the Daily Bread Food Bank\n",
    "would be appreciated.\n",
    "\n",
    "See you there!\n",
    "\n",
    "[Your city councillor]\n",
    "\n",
    "Topic: ```{{$input}}```\n",
    "\n",
    "Email:\n",
    "\"\"\"\n",
    "\n",
    "input_text = \"Community event in High Park\"\n",
    "\n",
    "email_writer = kernel.create_semantic_function(prompt, max_tokens=1000, temperature=0.3)\n",
    "output = email_writer(input_text)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50759f37",
   "metadata": {},
   "source": [
    "### Adjusting other settings\n",
    "\n",
    "The semantic functions have several optional arguments:\n",
    "- ``max_tokens`` sets the maximum response length. This is helpful for preventing overly long responses to keep costs under control. \n",
    "- ``temperature`` affects how words are selected when generating a response. A temperature of zero will always give the most likely response. Increasing the temperature allows for words other than the highest probability next words to be chosen. High temperatures can be thought of as more creative and unpredictable. \n",
    "- ``top_p`` determines the set of words that can be present in the response based on how likely they are to appear. E.g. ``top_p = 0.5`` will limit the response to the top 50\\% most likely words. When set to 0 or 1 (default value), no restrictions are applied on the set of possible words. \n",
    "- ``presence_penalty`` affects the tendency for a model to repeat words found in the input. Negative values reward repetition, while positive values penalize repetition. The default value is zero; no particular preference if the response contains words from the input. \n",
    "- ``frequency_penalty`` affects the amount of repetition in the response. Negative values reward repetition, while positive values penalize repetition. The default value is zero. \n",
    "\n",
    "We will illustrate use of the ``max_tokens`` and ``temperature`` settings below with a new semantic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9896920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the chicken cross the road?\n",
      "Punchline 1: To get to the other side, duh!\n",
      "Punchline 2: To get to the other side, duh!\n",
      "Punchline 3: To get to the other side, duh!\n",
      "Punchline 4: To get to the other side, duh!\n",
      "Punchline 5: To get to the other side, duh!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Write a funny punchline for the following joke:\n",
    "```{{$input}}```\n",
    "\"\"\"\n",
    "\n",
    "input_text = \"Why did the chicken cross the road?\"\n",
    "\n",
    "# Temperature of zero should always say \"To get to the other side\"\n",
    "# Also, note smaller value for max_tokens (joke punchlines are shorter than emails)\n",
    "joke_finisher_t0 = kernel.create_semantic_function(prompt, max_tokens=50, temperature=0)\n",
    "\n",
    "print(input_text)\n",
    "for i in range(5):\n",
    "    output = joke_finisher_t0(input_text)\n",
    "    print(f\"Punchline {i+1}: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bafa348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the chicken cross the road?\n",
      "Punchline 1: To get to the other side...of the street, not life.\n",
      "Punchline 2: To get to the silly punchline on the other side!\n",
      "Punchline 3: To get to the other side, duh!\n",
      "Punchline 4: To get to the other side, of course! (Classic, but still funny)\n",
      "Punchline 5: To get to the other side, duh!\n"
     ]
    }
   ],
   "source": [
    "# Temperature of 0.3: should start to see some variety in the joke punchlines\n",
    "joke_finisher_t3 = kernel.create_semantic_function(prompt, max_tokens=50, temperature=0.3)\n",
    "\n",
    "print(input_text)\n",
    "for i in range(5):\n",
    "    output = joke_finisher_t3(input_text)\n",
    "    print(f\"Punchline {i+1}: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee6783cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the chicken cross the road?\n",
      "Punchline 1: To prove to the possum that it could be done!\n",
      "Punchline 2: To get to the other side, duh!\n",
      "Punchline 3: To get to the idiot's house... Knock knock!\n",
      "Punchline 4: To prove to the possum that it could be done!\n",
      "Punchline 5: To prove it wasn't a chicken!\n"
     ]
    }
   ],
   "source": [
    "# Temperature of 0.9\n",
    "joke_finisher_t9 = kernel.create_semantic_function(prompt, max_tokens=50, temperature=0.9)\n",
    "\n",
    "print(input_text)\n",
    "for i in range(5):\n",
    "    output = joke_finisher_t9(input_text)\n",
    "    print(f\"Punchline {i+1}: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be14593",
   "metadata": {},
   "source": [
    "## Importing semantic functions from file\n",
    "\n",
    "In SK, related semantic functions can be grouped together under one \"Skill.\" The example semantic functions we have been modifying above are available under \"ExampleSkill\" in the skills directory of the workshop repository. The file structure is as follows: \n",
    "\n",
    "- Skills directory\n",
    "  - Semantic skill directory (\"ExampleSkill\")\n",
    "    - Semantic function directory (\"EmailWriter\")\n",
    "      - skprompt.txt (text file with prompt string)\n",
    "      - config.json (specify max_tokens, temperature, etc)\n",
    "    - Another semantic function directory (\"PunchlineWriter\")\n",
    "      - skprompt.txt\n",
    "      - config.json\n",
    "      \n",
    "``skprompt.txt`` contains the prompt text and nothing else. ``config.json`` handles parameters such as max_tokens and temperature, and also contains a short description of the semantic function. \n",
    "\n",
    "This directory structure and these file names are required by SK, otherwise it will raise an error when you try to load in your semantic skills & functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3753bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_directory = \"./tmls_workshop_backend/skills\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e5661b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (<ErrorCodes.ServiceError: 6>, 'OpenAI service failed to complete the chat', RateLimitError(message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d00c775327ceffab41225c1fa1d209d1 in your message.)', http_status=429, request_id=None))\n"
     ]
    }
   ],
   "source": [
    "# Loading in our ExampleSkill\n",
    "example_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"ExampleSkill\")\n",
    "\n",
    "# Semantic functions contained in ExampleSkill are accessed using square brackets and the function name\n",
    "output = example_skill['EmailWriter']('weekend road closures')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e190aadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because it's the coolest!\n"
     ]
    }
   ],
   "source": [
    "# Semantic functions contained in ExampleSkill are accessed as follows:\n",
    "output = example_skill['PunchlineWriter']('Why is vanilla the best ice cream flavour?')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb81aa5",
   "metadata": {},
   "source": [
    "## Native skills (python code)\n",
    "\n",
    "SK allows for the creation of code-based or \"native\" skills and functions. There are several situations where a native function is a better choice than a semantic function:\n",
    "- LLMs are not able to reliably work with numbers (imagine doing math by guessing likely digits!)\n",
    "- Some tasks are easy to do with code and there is no need for an LLM\n",
    "- Faster execution (no need to communicate with external model and wait for response)\n",
    "- Not being billed by the token\n",
    "\n",
    "The inputs and outputs can only be strings or the SKContext class. This will enable multiple skills/functions to be chained together to complete a multi-step request. The SKContext class is effectively a dictionary that can contain non-string arguments or multiple inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5553b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.skill_definition import sk_function\n",
    "\n",
    "# Our first native skill and function: adding a string of numbers together\n",
    "\n",
    "class BasicMathSkill:\n",
    "\n",
    "    @sk_function(\n",
    "        description=\"Add a list of numbers together\",\n",
    "        name=\"addNumbers\"\n",
    "    )\n",
    "    def add_numbers(self, input: str) -> str:\n",
    "        try:\n",
    "            return str(sum([float(x) for x in input.split()]))\n",
    "        except ValueError as e:\n",
    "            print(f\"Invalid input {input}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "041040f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "# Let's try adding 2, 3, and 4 together\n",
    "math_skill = kernel.import_skill(BasicMathSkill())\n",
    "output = math_skill[\"addNumbers\"](\"2 3 4\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "540a09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.skill_definition import sk_function_context_parameter\n",
    "from semantic_kernel import SKContext\n",
    "\n",
    "# \"Advanced\" math skill: dividing two numbers\n",
    "\n",
    "class AdvancedMathSkill:\n",
    "\n",
    "    @sk_function(\n",
    "        description=\"Divide one number by another number\",\n",
    "        name=\"divideNumbers\"\n",
    "    )\n",
    "    @sk_function_context_parameter(name=\"numerator\", description=\"Number being divided\")\n",
    "    @sk_function_context_parameter(name=\"denominator\", description=\"Number that numerator is divided by\")\n",
    "    def divide_numbers(self, context: SKContext) -> str:\n",
    "        try:\n",
    "            return str(context[\"numerator\"] / context[\"denominator\"]) \n",
    "        except ValueError as e:\n",
    "            print(f\"Invalid input {context['numerator']} {context['denominator']}\")\n",
    "            raise e\n",
    "            \n",
    "new_math_skill = kernel.import_skill(AdvancedMathSkill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae979e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.142857142857143\n"
     ]
    }
   ],
   "source": [
    "# 22/7 is a handy approximation for pi, so let's calculate that\n",
    "context_variables = sk.ContextVariables(variables={\n",
    "    \"numerator\": 22,\n",
    "    \"denominator\": 7\n",
    "})\n",
    "\n",
    "output = new_math_skill[\"divideNumbers\"].invoke(variables=context_variables).result\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c555b",
   "metadata": {},
   "source": [
    "## Planner\n",
    "\n",
    "The planner is what bridges the gap between having a series of skills available to the kernel and automating the use of these skills to accomplish a given task. This is another power of LLMs: not only can we ask the model to write emails or tell jokes, but we can ask it to parse the input from a user and come up with a plan to generate a response. \n",
    "\n",
    "The planner prompt gives context to the model: the purpose of the application, the desire to parse the input into an action plan, and descriptions of all of the available skills. The skills loaded into the kernel are described automatically, so it is important to pick clear skill/function names and to fill out the description strings when creating them. \n",
    "\n",
    "The planner prompt asks the model for a formatted output plan (e.g. JSON or XML). Once the model has responded, code aspects of the planner class can handle the execution of the plain. The planner in the python version of SK is still under development, but we can have a quick look at it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68ffbb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning.basic_planner import BasicPlanner\n",
    "planner = BasicPlanner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "466c4007",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"\n",
    "I want to come up with an election-related joke and send it in an email\n",
    "\"\"\"\n",
    "plan = await planner.create_plan_async(ask, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "35fea42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"input\": \"election-related joke\",\n",
      "    \"subtasks\": [\n",
      "        {\"function\": \"ExampleSkill.PunchlineWriter\"},\n",
      "        {\"function\": \"ExampleSkill.EmailWriter\"}\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(plan.generated_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c75cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await planner.execute_plan_async(plan, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5fd30f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Clarification on Recent Personal Matters\n",
      "\n",
      "Dear Neighbours,\n",
      "\n",
      "I hope this email finds you well. I am writing to address recent rumors and speculation regarding my personal life. It has come to my attention that some of you may have heard that I recently broke up with my girlfriend. While I understand that personal matters can be of interest to some, I want to clarify that this decision was made solely because I wanted to focus on my running mate and the upcoming election.\n",
      "\n",
      "As a public figure, I understand that my personal life may be subject to scrutiny. However, I want to assure you that my commitment to serving our community remains unwavering. I am fully dedicated to working with my running mate to address the issues that matter most to our constituents.\n",
      "\n",
      "I appreciate your understanding and support during this time. If you have any questions or concerns, please do not hesitate to reach out to me directly.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "[Your Name]\n",
      "\n",
      "P.S. If you are interested in learning more about my campaign and platform, please visit my website at [insert website link]. Thank you.\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e690cd9",
   "metadata": {},
   "source": [
    "### Congratulations! You've learned the basics of Microsoft Semantic Kernel! :) \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
